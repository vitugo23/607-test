---
title: "Project 4"
author: "Victor Torres"
date: "2024-04-10"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Introduction

"For this project, you can start with a spam/ham dataset, then predict the class of new documents (either withheld from the training dataset or from another source such as your own spam folder)". I decided to use the spam/ham dataset provided by the instructor, I created a folder to unzip the files on it, and from there import it to R from my C drive.

### Load libraries required for this project
I am going to use two new packages that I think it would be useful for this project, "NLP" which is used for Natural Language Processing, and also "tm", a library that is used for collecting data from corpus. In addition, I am going to use the e1071 package which is new for me, this library is used for model prediction, it contains the Naive Bayes classifier that I will use for predicting this model, another new package to me is the CARET package, I will use it to produce a matrix to the clasifier.

```{r libraries}
library(tidyverse)
library(tm)
library(NLP)
library(e1071)
library(caret)
library(magrittr)

```

### Import both easy_ham and spam files into R.

I'm using the list.files function which produces a character vector of the names of files or directories in the named directory.

```{r import files}
spam_folder <- "C:/Users/vitug/OneDrive/Desktop/DATA_607/Project4/spamham/spam_folder"
easy_folder <- "C:/Users/vitug/OneDrive/Desktop/DATA_607/Project4/spamham/easy_folder"

length(list.files(path = spam_folder))
length(list.files(path = easy_folder))

```

### Create a dataframe of the spam_folder, using list.files and lapply function, unnest the files by text and group by file. 

```{r spam folder}
spam_files <- list.files(path = spam_folder, full.names = TRUE)
spam <- list.files(path = spam_folder) %>%
  as.data.frame() %>%
  set_colnames("file") %>%
  mutate(text = lapply(spam_files, read_lines)) %>%
  unnest(c(text)) %>%
  mutate(class = "spam",
         spam = 1) %>%
  group_by(file) %>%
  mutate(text = paste(text, collapse = " ")) %>%
  ungroup() %>%
  distinct()
```

### Perform the same operation with the easy_folder.

```{r easy folder}
ham_files <- list.files(path = easy_folder, full.names = TRUE) 
ham <- list.files(path = easy_folder) %>%
  as.data.frame() %>%
  set_colnames("file") %>%
  mutate(text = lapply(ham_files, read_lines)) %>%
  unnest(c(text)) %>%
  mutate(class = "ham",
         spam = 0) %>%
  group_by(file) %>%
  mutate(text = paste(text, collapse = " ")) %>%
  ungroup() %>%
  distinct()
```

### Cleaning and Tyding data using the rbind function to combine dataframe by rows,use the str_replace function to remove empty spaces in columns and rows, and the content_transformer function to replace puntuation signs with an space.

```{r tyding}
ham_spam <- rbind(ham, spam) %>%
  select(class, spam, file, text)

ham_spam$text <- ham_spam$text %>%
  str_replace(.,"[\\r\\n\\t]+", "")

replacePunctuation <- content_transformer(function(x) {return (gsub("[[:punct:]]", " ", x))})
head(ham_spam)
```

### Create the corpus using TM library, and using some of the tm functions to clean the data on it, create a doxument term matrix, and removing some unused words(-10) with the remove sparse terms function

```{r tm corpus}
corpus <- Corpus(VectorSource(ham_spam$text)) %>%
  tm_map(content_transformer(tolower)) %>%
  tm_map(removeWords, stopwords("english")) %>%
  tm_map(replacePunctuation) %>%
  tm_map(removeNumbers) %>%
  tm_map(stripWhitespace)

dtm <- DocumentTermMatrix(corpus)

dtm <- removeSparseTerms(dtm, 1-(10/length(corpus)))

inspect(dtm)
dim(dtm)
```

### I am going to convert the 'DTM' to a dataframe, also add a column to get the results of spam or not spam, and mutate the spam column into a factor.

```{r working with dtm}
mail_dtm <- dtm %>%
  as.matrix() %>%
  as.data.frame() %>%
  sapply(., as.numeric) %>%
  as.data.frame() %>%
  mutate(class = ham_spam$class) %>%
  select(class, everything())
  mail_dtm$class <- as.factor(mail_dtm$class)
```

### Set the sample_size to 0.85 as a training data, set a sed, and setup the training DTM with the test data.

```{r setting training and test}
sample_size <- floor(0.85 * nrow(mail_dtm))

set.seed(2779)
index <- sample(seq_len(nrow(mail_dtm)), size = sample_size)
  
dtm_train <- mail_dtm[index,]
dtm_test <-  mail_dtm[-index,]

training_lab <- dtm_train$class
test_lab <- dtm_test$class

prop.table(table(training_lab))
prop.table(table(test_lab))
```

### Finalize the training model using the Naive Bayes Model, dispalying the results in the table called matrix and statistics. 

```{r model classifier}
dtm_train[ , 2:1914] <- ifelse(dtm_train[ , 2:1914] == 0, "No", "Yes")
dtm_test[ , 2:1914] <- ifelse(dtm_test[ , 2:1914] == 0, "No", "Yes")

model_classifier <- naiveBayes(dtm_train, training_lab) 

test_pred <- predict(model_classifier, dtm_test)

confusionMatrix(test_pred, test_lab, positive = "spam", 
                dnn = c("Prediction","Actual")) 
```

### I created a small visualization of words in ham_spam, using wordcloud

```{r wordcloud}
library(wordcloud)
wordcloud(ham_spam, max.words = 100, random.order = FALSE, rot.per=0.15, min.freq=5, colors = brewer.pal(8, "Dark2"))
```


## Conclussion.

So far, this project has been the most challenging in this course, I been exposed to a bunch of new ways to work with data, new libraries, and methods to convert and analyze dataframes.I did a deep research of how to work with predictions in R, I found out that the e1071 package contains the Naive Bayes classification algorithm which is" a simple probabilistic classifiers based on applying Baye’s theorem with strong(Naive) independence assumptions between the features or variables." and also is called "Naive" because it makes the assumption that the occurrence of a certain feature is independent of the occurrence of other features.

### Sources.

Geeks for geeks (Naive Bayes Classifier in R Programming)
https://www.geeksforgeeks.org/naive-bayes-classifier-in-r-programming/

DataCamp (Machine learning with caret in R)
https://campus.datacamp.com/courses/machine-learning-with-caret-in-r/regression-models-fitting-and-evaluating-their-performance?ex=1

R documentation (prediction: Function to create prediction objects)
https://www.rdocumentation.org/packages/ROCR/versions/1.0-11/topics/prediction

Data Flair Training (e1071 Package – Perfect Guide on SVM Training & Testing Models in R)
https://data-flair.training/blogs/e1071-in-r/#:~:text=The%20e1071%20Package%3A&text=Offers%20quick%20and%20easy%20implementation,classification%20mode%20and%20cross%2Dvalidation.






